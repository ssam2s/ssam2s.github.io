<!DOCTYPE HTML>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MBNHLWD0TG"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-MBNHLWD0TG');
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Junhyeok Seo</title>

    <meta name="author" content="Junhyeok Seo">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Junhyeok Seo
                </p>
                <p>
                  I am first-year M.S. student in Department of Artificial Intelligence at Kyungpook National University, advised by Prof. Donggyu Lee</a>.
                </p>
                <p>
                  Prior to KNU, I received B.S. degrees in <a href="https://ce.kumoh.ac.kr/ce/index.do">Department of Computer Engineering at Kumoh National Institute of Technology</a>, advised by Prof. Hyeonju Yoon</a>.
                  I worked on diverse topics in computer vision, including Multimodal Learning and Imitation Learning.
                </p>
                <p style="text-align:center">
                  <a href="mailto:ssam2s@knu.ac.kr">Email</a> &nbsp;/&nbsp;
                  <a href="https://www.instagram.com/xeo_xxn">Instagram</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ssam2s">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/jhseo.jpg"><img style="width:60%;max-width:60%" alt="profile photo" src="images/jhseo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center; font-size: medium;">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/ADXgCz29uBw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  <br>
                  The person playing the guitars in the video is me (w/ my friend Daehyun Kim).
                  <br>
                  (We extracted the voice of <a href="https://www.youtube.com/channel/UC3SyT4_WLHzN7JmHQwKQZww">IU</a>, and put it on our band's music.)
                </p>
              </td>
            </tr>
          </table> -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <p>
                  <ul>
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">12/2024: Presented a paper on single image super-resolution at <a href="https://www.kiise.or.kr/conference/KSC/2024/">KSC 2024</a>.
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">09/2024: Received Merit Scholarship(IH003) from KNU.
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">08/2024: Won a top prize(The Mayor of Daegu Metropolitan City Award) of the <a href="https://n.news.naver.com/article/030/0003228170?sid=102">ÎåÄÍµ¨Í¥ëÏó≠Ïãú Í≥µÍ≥µÎç∞Ïù¥ÌÑ∞ ÌôúÏö© Ï∞ΩÏóÖÍ≤ΩÏßÑÎåÄÌöå</a>.
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">03/2024: Received Merit Scholarship(IH003) from KNU.
                    <li style="list-style-position:inside;margin:0;padding:0;text-align:left;">03/2024: Joined <a href="https://sites.google.com/view/cvmilab">Computer Vision and Machine Intelligence Lab.</a> at Kyungpook National University.
                  </ul>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Research</h2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Vehicle Detection System.png' width="160" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/Vehicle Detection System.pdf">
                <span class="papertitle">Deep Learning-Based Vehicle Model and License Plate Identification System using Vehicle Image</span>
              </a>
              <br>
              <strong>Junhyeok Seo</strong>, Hyeonju Yoon
              <br>
              <br>
              <span class="tag blue">KIIT, 2022</span><span class="tag orange">Gold Award</span>
              <br>
                - Winning a Gold Award for Outstanding Paper
              <br>
                - Domestic Conference
              <br>
              <br>
              <p>
                I proposed a novel framework for a vehicle model recognition and license plate identification system using YOLOv5, enabling both tasks to be carried out simultaneously. Proposed image processing algorithm for estimating the region of license plate is much lighter than previous deep learning based method.
                </p>
            </td>
          </tr>

          <tr onmouseout="vqbet_stop()" onmouseover="vqbet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='vqbet_video'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vqbet_button_video.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vqbet_button_thumbnail.png' width="160" height="160">
              </div>
              <script type="text/javascript">
                function vqbet_start() {
                  document.getElementById('vqbet_video').style.opacity = "1";
                }
    
                function vqbet_stop() {
                  document.getElementById('vqbet_video').style.opacity = "0";
                }
                vqbet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sjlee.cc/vq-bet">
                <span class="papertitle">Behavior Generation with Latent Actions</span>
              </a>
              <br>
              <strong>Seungjae Lee</strong>, Yibin Wang, Haritheja Etukuru, H. Jin Kim, Nur Muhammad Mahi Shafiullah, Lerrel Pinto
              <br>
              <span class="tag green">ICML, 2024</span> <span class="tag red">Spotlight</span> (Top: 3.5%)
              <br>
                + RSS 2024 Workshop SemRob, "Oral spotlights"
              <br>
                + ICML 2024 Workshop MFM-EAI, "Outstanding Paper Award - Winner"
              <br>
              <br>
              <a href="https://sjlee.cc/vq-bet">project website</a>/
              <a href="https://arxiv.org/abs/2403.03181">arXiv</a>/
              <a href="https://github.com/jayLEE0301/vq_bet_official">github</a>/
              <a href="https://github.com/huggingface/lerobot">ü§ó Lerobot Library</a>
              <p></p>
              <p>
                In this work, we present Vector-Quantized Behavior Transformer (VQ-BeT), a versatile model for behavior generation that handles multimodal action prediction, conditional generation, and partial observations. Across seven environments including simulated manipulation, autonomous driving, and robotics, VQ-BeT improves on state-of-the-art models such as BeT and Diffusion Policies.
                </p>
            </td>
          </tr>

          <tr onmouseout="cqm_stop()" onmouseover="cqm_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cqm_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/cqm_video.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/cqm_image.png' width="160">
              </div>
              <script type="text/javascript">
                function cqm_start() {
                  document.getElementById('cqm_image').style.opacity = "1";
                }
    
                function cqm_stop() {
                  document.getElementById('cqm_image').style.opacity = "0";
                }
                cqm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2310.17330">
                <span class="papertitle">CQM: Curriculum Reinforcement Learning with a Quantized World Model</span>
              </a>
              <br>
              <strong>Seungjae Lee</strong>, Daesol Cho, Jonghae Park, H Jin Kim
              <br>
              <span class="tag blue">NeurIPS, 2023</span> (Acceptance Rate: 26.07%)
              <br>
              <a href="https://arxiv.org/abs/2310.17330">arXiv</a>
              <p></p>
              <p>
              Previous approaches often face challenges when they generate curriculum goals in a high-dimensional space. To alleviate it, we propose a novel curriculum method for agents that automatically defines the semantic goal space, and suggests curriculum goals over it.
              </p>
            </td>
          </tr>
    
    
          <tr onmouseout="d2c_stop()" onmouseover="d2c_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='d2c_image'>
                  <img src='images/d2c_image2.png' width="160" height="160"></div>
                <img src='images/d2c_image.png' width="160" height="160">
              </div>
              <script type="text/javascript">
                function d2c_start() {
                  document.getElementById('d2c_image').style.opacity = "1";
                }
    
                function d2c_stop() {
                  document.getElementById('d2c_image').style.opacity = "0";
                }
                d2c_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2310.19261">
                <span class="papertitle">Diversify Conquer: Outcome-directed Curriculum RL via Out-of-Distribution Disagreement</span>
              </a>
              <br>
              Daesol Cho, <strong>Seungjae Lee</strong>, H Jin Kim
              <br>
              <span class="tag blue">NeurIPS, 2023</span> (Acceptance Rate: 26.07%)
              <br>
              <a href="https://arxiv.org/abs/2310.19261">arXiv</a>
              <p></p>
              <p>
                Unlike previous curriculum learning methods, D2C requires only a few examples of desired outcomes and works in any environment, regardless of its geometry or the distribution of the desired outcome examples.
              </p>
            </td>
          </tr>
    

          <tr onmouseout="snerl_stop()" onmouseover="snerl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='snerl_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/snerl_video.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                <img src='images/snerl_image.png' width="160" height="160">
              </div>
              <script type="text/javascript">
                function snerl_start() {
                  document.getElementById('snerl_image').style.opacity = "1";
                }
    
                function snerl_stop() {
                  document.getElementById('snerl_image').style.opacity = "0";
                }
                snerl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2301.11520">
                <span class="papertitle">SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning</span>
              </a>
              <br>
              Dongseok Shim*, <strong>Seungjae Lee*</strong>, H Jin Kim
              <br>
              (*equal contribution)
              <br>
              <span class="tag green">ICML, 2023</span> (Acceptance Rate: 27.96%)
              <br>
              <a href="https://arxiv.org/abs/2301.11520">arXiv</a> /
              <a href="https://github.com/jayLEE0301/snerl_official">github</a>
              <p></p>
              <p>
                We present Semantic-aware Neural Radiance Fields for Reinforcement Learning (SNeRL), which jointly optimizes semantic-aware neural radiance fields (NeRF) with a convolutional encoder to learn 3D-aware neural implicit representation from multi-view images.
              </p>
            </td>
          </tr>



          <tr onmouseout="outpace_stop()" onmouseover="outpace_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='outpace_image'>
                  <img src='images/outpace_image.png' width="160" height="160"></div>
                <img src='images/outpace_image2.png' width="160" height="160">
              </div>
              <script type="text/javascript">
                function outpace_start() {
                  document.getElementById('outpace_image').style.opacity = "1";
                }
    
                function outpace_stop() {
                  document.getElementById('outpace_image').style.opacity = "0";
                }
                outpace_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2301.11741">
                <span class="papertitle">Outcome-directed Reinforcement Learning by Uncertainty & Temporal Distance-Aware Curriculum Goal Generation</span>
              </a>
              <br>
              Daesol Cho*, <strong>Seungjae Lee*</strong>, H Jin Kim
              <br>
              (*equal contribution)
              <br>
              <span class="tag orange">ICLR, 2023</span> <span class="tag red">Spotlight</span> (Top: 5.65%)
              <br>
              <a href="https://arxiv.org/abs/2301.11741">arXiv</a> /
              <a href="https://github.com/jayLEE0301/outpace_official">github</a>
              <p></p>
              <p>
                We propose an uncertainty & temporal distance-aware curriculum goal generation method for the outcome-directed RL via solving a bipartite matching problem. It can provide precisely calibrated guidance of the curriculum to the desired outcome states.
              </p>
            </td>
          </tr>

          <tr onmouseout="ijcas_stop()" onmouseover="ijcas_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ijcas_image'>
                  <img src='images/ijcas_image2.png' width="160" height="160"></div>
                <img src='images/ijcas_image.png' width="160" height="100">
              </div>
              <script type="text/javascript">
                function ijcas_start() {
                  document.getElementById('ijcas_image').style.opacity = "1";
                }
    
                function ijcas_stop() {
                  document.getElementById('ijcas_image').style.opacity = "0";
                }
                ijcas_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://jaylee0301.github.io">
                <span class="papertitle">Deep End-to-End Imitation Learning for Missile Guidance with Infrared Images</span>
              </a>
              <br>
              <strong>Seungjae Lee</strong>, Jongho Shin, Hyeong-Geun Kim, Daesol Cho, H. Jin Kim
              <br>
              <span class="tag gray">IJCAS, 2023</span>
              <br>
              <p></p>
              <p>
                We propose an end-to-end missile guidance algorithm from raw infrared image pixels by imitating a conventional guidance law which leverages privileged data. 
              </p>
            </td>
          </tr>
    
    

          <tr onmouseout="dhrl_stop()" onmouseover="dhrl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dhrl_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/dhrl_video.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                <img src='images/dhrl_image.png' width="160" height="160">
              </div>
              <script type="text/javascript">
                function dhrl_start() {
                  document.getElementById('dhrl_image').style.opacity = "1";
                }
    
                function dhrl_stop() {
                  document.getElementById('dhrl_image').style.opacity = "0";
                }
                dhrl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.05150">
                <span class="papertitle">DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical Reinforcement Learning</span>
              </a>
              <br>
              <strong>Seungjae Lee</strong>, Jigang Kim, Inkyu Jang, H. Jin Kim
              <br>
              <span class="tag blue">NeurIPS, 2022</span> <span class="tag red">Oral</span> (Top: 1.76%)
              <br>
              <a href="https://arxiv.org/abs/2210.05150">arXiv</a> /
              <a href="https://github.com/jayLEE0301/dhrl_official">github</a>
              <p></p>
              <p>
                DHRL provides a freely stretchable high-level action interval, which facilitates longer temporal abstraction and faster training in complex tasks.
              </p>
            </td>
          </tr>




      
      <tr onmouseout="iros_stop()" onmouseover="iros_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='iros_image'>
              <img src='images/iros_image2.png' width="160" height="160"></div>
            <img src='images/iros_image.png' width="160" height="160">
          </div>
          <script type="text/javascript">
            function iros_start() {
              document.getElementById('iros_image').style.opacity = "1";
            }

            function iros_stop() {
              document.getElementById('iros_image').style.opacity = "0";
            }
            iros_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2107.06484">
            <span class="papertitle">Robust and Recursively Feasible Real-Time Trajectory Planning in Unknown Environments</span>
          </a>
          <br>
          Inkyu Jang, Dongjae Lee, <strong>Seungjae Lee</strong>, H Jin Kim
          <br>
          <span class="tag purple">IROS, 2021</span> (Acceptance Rate: 45%)
          <br>
          <a href="https://arxiv.org/abs/2107.06484">arXiv</a>
          <p></p>
          <p>
            We propose a real-time robust planner that recursively guarantees persistent feasibility without any need of braking. 
          </p>
        </td>
      </tr>
          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Projects</h2>
              </td>
            </tr>

        
      <tr onmouseout="hdx_stop()" onmouseover="hdx_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='hdx_image'><video  width=100% height=auto muted autoplay loop>
            <source src="images/excavator.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/hdx_image.png' width="160">
          </div>
          <script type="text/javascript">
            function hdx_start() {
              document.getElementById('hdx_image').style.opacity = "1";
            }

            function hdx_stop() {
              document.getElementById('hdx_image').style.opacity = "0";
            }
            hdx_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <span class="papertitle">Training Excavator Virtual Driver based on Inverse RL</span>
          <br>
          
          <p></p>
          <p>
            with HD Hyundai Heavy Industries Co., Ltd.
            <br>
            <em>Apr. 2023 - Mar. 2024</em>
          </p>
        </td>
      </tr>


      <tr onmouseout="ic01_stop()" onmouseover="ic01_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='ic01_image'><video  width=100% height=auto muted autoplay loop>
            <source src="images/missile.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/ic01_image.png' width="160">
          </div>
          <script type="text/javascript">
            function ic01_start() {
              document.getElementById('ic01_image').style.opacity = "1";
            }

            function ic01_stop() {
              document.getElementById('ic01_image').style.opacity = "0";
            }
            ic01_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <span class="papertitle">End-to-End Machine Learning Based Guidance Research</span>
          <br>
          with Korean Agency for Defense Development (ADD)
          <br>
          <em>May. 2021 - Apr. 2023</em>
          </p>
        </td>
      </tr>
          </tbody></table>








          
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Awards and Achievements</h2>
              </td>
              
            </tr>
            
          </tbody></table>

          <ul>
            <li>[Scholarship] Dashin Songchon Foundation (Aug 2024 - Present)</li>
            <li>[Awards] Graduated Summa Cum Laude, Seoul National University (1st prize in Department of Aerospace Engineering)</li>
            <li>[Scholarship] Hyundai Motor Chung Mong-Koo Foundation (Aug 2021 - Jul2023)</li>
            <li>[Awards] NeurIPS Scholar Award</li>
            <li>[Awards] Global Excellence Scholarship 2022, Hyundai Motor Chung Mong-Koo Foundation</li>
            <li>[Awards] Best poster competition, SNU Artificial Intelligence Institute Spring Retreat</li>
            <li>[Awards] Global Excellence Scholarship 2023, Hyundai Motor Chung Mong-Koo Foundation</li>
          </ul>


          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Academic Services</h2>
              </td>
              
            </tr>
            
          </tbody></table>

          <ul>
            <li>Program Committee, RSS 2024 SemRob Workshop</li>
            <li>Conference reviewer for ICML'22 '24</li>
            <li>Conference reviewer for IROS'23</li>
            <li>Conference reviewer for NeurIPS'23</li>
            <li>Conference reviewer for ICLR'24 '25</li>
            <li>Conference reviewer for ICRA'24 '25</li>
            <li>Conference reviewer for AAAI'25</li>
          </ul>


          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Professional Experience</h2>
              </td>
              
            </tr>
            
          </tbody></table>

          <ul>
            <li style="display: flex; align-items: center;">
              <img src="images/tri.png" alt="Toyota Research Institute" style="width: 100px; height: auto; margin-right: 10px;">
              [Internship] Toyota Research Institute, 2025.5 - 2025.8
            </li>
            <br>
            <li style="display: flex; align-items: center;">
              <img src="images/samsung.png" alt="Samsung Electronics" style="width: 100px; height: auto; margin-right: 10px;">
              [Internship] Samsung Electronics, Deep Learning Algorithm Team / Device Solutions (DS), 2020.7 - 2020.9
            </li>
            <br>
            <li style="display: flex; align-items: center;">
              <img src="images/deepest.png" alt="Deepest" style="width: 100px; height: auto; margin-right: 10px;">
              [Research Group] <a href="https://deepest.ai/">Deepest</a>. (SNU Deep Learning Society), 2020.9 - 2022.2
            </li>
          </ul>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Source code credit to <a href="https://jonbarron.info/" target="_blank">Dr. Jon Barron</a></p>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
